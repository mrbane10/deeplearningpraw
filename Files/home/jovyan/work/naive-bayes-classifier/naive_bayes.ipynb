{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3545df95",
   "metadata": {},
   "source": [
    "# Naive Bayes Spam Email Classifier\n",
    "\n",
    "A machine learning project implementing the Naive Bayes algorithm from scratch for email spam detection. This project demonstrates the importance of numerical stability in probabilistic models and achieves 99.21% accuracy on the test dataset.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Project Overview](#project-overview)\n",
    "2. [Data Loading and Exploration](#data-loading-and-exploration)\n",
    "3. [Data Preprocessing](#data-preprocessing)\n",
    "4. [Model Implementation](#model-implementation)\n",
    "5. [Model Training](#model-training)\n",
    "6. [Evaluation and Results](#evaluation-and-results)\n",
    "7. [Demo and Conclusion](#demo-and-conclusion)\n",
    "\n",
    "---\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This project implements a Naive Bayes classifier for spam email detection with the following key features:\n",
    "\n",
    "- **From-scratch implementation** of Naive Bayes algorithm\n",
    "- **Numerical stability** handling using log-space computations\n",
    "- **Text preprocessing** with stopword removal and tokenization\n",
    "- **Comprehensive evaluation** with multiple metrics\n",
    "- **Performance comparison** between standard and log-space implementations\n",
    "\n",
    "**Key Achievement**: Improved model accuracy from 84.82% to 99.21% by implementing log-space computations to handle numerical underflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90222438",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kaisarimtiyaz/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/kaisarimtiyaz/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afc4ffb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Overview:\n",
      "========================================\n",
      "Total emails: 5,728\n",
      "Spam emails: 1,368 (23.88%)\n",
      "Ham emails: 4,360 (76.12%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0  Subject: naturally irresistible your corporate...     1\n",
       "1  Subject: the stock trading gunslinger  fanny i...     1\n",
       "2  Subject: unbelievable new homes made easy  im ...     1\n",
       "3  Subject: 4 color printing special  request add...     1\n",
       "4  Subject: do not have money , get software cds ...     1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the email dataset\n",
    "dataframe_emails = pd.read_csv('emails.csv')\n",
    "\n",
    "# Display dataset overview\n",
    "print(\"Dataset Overview:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Total emails: {len(dataframe_emails):,}\")\n",
    "print(f\"Spam emails: {dataframe_emails.spam.sum():,} ({dataframe_emails.spam.sum()/len(dataframe_emails):.2%})\")\n",
    "print(f\"Ham emails: {len(dataframe_emails) - dataframe_emails.spam.sum():,} ({1-dataframe_emails.spam.sum()/len(dataframe_emails):.2%})\")\n",
    "\n",
    "# Display first few rows\n",
    "dataframe_emails.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f274a1",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Implementing text preprocessing functions to clean and prepare the email data for training. This includes:\n",
    "\n",
    "- **Email shuffling** to avoid bias in train/test splits\n",
    "- **Subject line removal** (first 9 characters)\n",
    "- **Tokenization** and **stopword removal**\n",
    "- **Punctuation filtering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0469836f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing completed!\n",
      "Sample preprocessed email: ['energy' 'derivatives' 'conference' 'may' '29' 'toronto' 'good' 'morning'\n",
      " 'amy' 'vince']\n"
     ]
    }
   ],
   "source": [
    "def preprocess_emails(df):\n",
    "    \"\"\"\n",
    "    Preprocesses email data by shuffling and extracting content.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing email data with 'text' and 'spam' columns\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (email_content, labels) as numpy arrays\n",
    "    \"\"\"\n",
    "    # Shuffle dataset to avoid bias\n",
    "    df = df.sample(frac=1, ignore_index=True, random_state=42)\n",
    "    \n",
    "    # Remove \"Subject:\" prefix (first 9 characters)\n",
    "    X = df.text.apply(lambda x: x[9:]).to_numpy()\n",
    "    Y = df.spam.to_numpy()\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "def preprocess_text(X):\n",
    "    \"\"\"\n",
    "    Preprocesses text data by removing stopwords and punctuation.\n",
    "    \n",
    "    Args:\n",
    "        X: Text data (string or array of strings)\n",
    "        \n",
    "    Returns:\n",
    "        list: Preprocessed text with stopwords and punctuation removed\n",
    "    \"\"\"\n",
    "    # Create stopword and punctuation set\n",
    "    stop = set(stopwords.words('english') + list(string.punctuation))\n",
    "    \n",
    "    # Handle single string input\n",
    "    if isinstance(X, str):\n",
    "        X = np.array([X])\n",
    "    \n",
    "    X_preprocessed = []\n",
    "    for email in X:\n",
    "        # Tokenize, lowercase, and filter stopwords/punctuation\n",
    "        tokens = np.array([word.lower() for word in word_tokenize(email) \n",
    "                          if word.lower() not in stop]).astype(X.dtype)\n",
    "        X_preprocessed.append(tokens)\n",
    "    \n",
    "    return X_preprocessed[0] if len(X) == 1 else X_preprocessed\n",
    "\n",
    "# Apply preprocessing\n",
    "X, Y = preprocess_emails(dataframe_emails)\n",
    "X_treated = preprocess_text(X)\n",
    "\n",
    "print(\"Preprocessing completed!\")\n",
    "print(f\"Sample preprocessed email: {X_treated[0][:10]}\")  # Show first 10 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8cc43ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Split Summary:\n",
      "==============================\n",
      "Training set: 4,582 emails\n",
      "  - Spam: 1,114 (24.31%)\n",
      "  - Ham: 3,468 (75.69%)\n",
      "\n",
      "Test set: 1,146 emails\n",
      "  - Spam: 254 (22.16%)\n",
      "  - Ham: 892 (77.84%)\n"
     ]
    }
   ],
   "source": [
    "# Train-test split (80-20)\n",
    "TRAIN_SIZE = int(0.80 * len(X_treated))\n",
    "\n",
    "X_train = X_treated[:TRAIN_SIZE]\n",
    "Y_train = Y[:TRAIN_SIZE]\n",
    "X_test = X_treated[TRAIN_SIZE:]\n",
    "Y_test = Y[TRAIN_SIZE:]\n",
    "\n",
    "print(\"Dataset Split Summary:\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"Training set: {len(X_train):,} emails\")\n",
    "print(f\"  - Spam: {sum(Y_train == 1):,} ({sum(Y_train == 1)/len(Y_train):.2%})\")\n",
    "print(f\"  - Ham: {sum(Y_train == 0):,} ({sum(Y_train == 0)/len(Y_train):.2%})\")\n",
    "print(f\"\\nTest set: {len(X_test):,} emails\")\n",
    "print(f\"  - Spam: {sum(Y_test == 1):,} ({sum(Y_test == 1)/len(Y_test):.2%})\")\n",
    "print(f\"  - Ham: {sum(Y_test == 0):,} ({sum(Y_test == 0)/len(Y_test):.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c3b475",
   "metadata": {},
   "source": [
    "## Model Implementation\n",
    "\n",
    "### Core Naive Bayes Functions\n",
    "\n",
    "Implementing the mathematical foundation of the Naive Bayes classifier:\n",
    "\n",
    "1. **Word Frequency Calculation**: Count word occurrences in spam vs ham emails\n",
    "2. **Probability Estimation**: Calculate P(word|class) using frequency counts\n",
    "3. **Email Classification**: Apply Bayes' theorem for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfa19d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_frequency(X, Y):\n",
    "    \"\"\"\n",
    "    Calculate word frequencies for spam and ham emails with Laplace smoothing.\n",
    "    \n",
    "    Args:\n",
    "        X: Array of preprocessed emails\n",
    "        Y: Array of labels (1=spam, 0=ham)\n",
    "        \n",
    "    Returns:\n",
    "        dict: Word frequency dictionary with spam/ham counts\n",
    "    \"\"\"\n",
    "    word_dict = {}\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        email = set(X[i])  # Remove duplicates within email\n",
    "        cls = Y[i]\n",
    "        \n",
    "        for word in email:\n",
    "            if word not in word_dict:\n",
    "                # Initialize with Laplace smoothing (add 1)\n",
    "                word_dict[word] = {\"spam\": 1, \"ham\": 1}\n",
    "                \n",
    "            # Increment count for appropriate class\n",
    "            if cls == 0:\n",
    "                word_dict[word][\"ham\"] += 1\n",
    "            else:\n",
    "                word_dict[word][\"spam\"] += 1\n",
    "                \n",
    "    return word_dict\n",
    "\n",
    "def prob_word_given_class(word, cls, word_frequency, class_frequency):\n",
    "    \"\"\"Calculate conditional probability P(word|class)\"\"\"\n",
    "    return word_frequency[word][cls] / class_frequency[cls]\n",
    "\n",
    "def prob_email_given_class(treated_email, cls, word_frequency, class_frequency):\n",
    "    \"\"\"Calculate P(email|class) using independence assumption\"\"\"\n",
    "    prob = 1\n",
    "    for word in treated_email:\n",
    "        if word in word_frequency:\n",
    "            prob *= word_frequency[word][cls] / class_frequency[cls]\n",
    "    return prob\n",
    "\n",
    "def log_prob_email_given_class(treated_email, cls, word_frequency, class_frequency):\n",
    "    \"\"\"Calculate log P(email|class) to prevent numerical underflow\"\"\"\n",
    "    log_prob = 0\n",
    "    for word in treated_email:\n",
    "        if word in word_frequency:\n",
    "            log_prob += np.log(word_frequency[word][cls] / class_frequency[cls])\n",
    "    return log_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207dc908",
   "metadata": {},
   "source": [
    "### Classifier Implementations\n",
    "\n",
    "Two versions of the Naive Bayes classifier:\n",
    "\n",
    "1. **Standard Implementation**: Direct probability calculation\n",
    "2. **Log-space Implementation**: Uses logarithms to handle numerical stability issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e642f347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(treated_email, word_frequency, class_frequency, return_likelihood=False):\n",
    "    \"\"\"\n",
    "    Standard Naive Bayes classifier implementation.\n",
    "    \n",
    "    Args:\n",
    "        treated_email: Preprocessed email content\n",
    "        word_frequency: Word frequency dictionary\n",
    "        class_frequency: Class frequency dictionary\n",
    "        return_likelihood: Whether to return likelihood values\n",
    "        \n",
    "    Returns:\n",
    "        int: 1 for spam, 0 for ham (or likelihood tuple if requested)\n",
    "    \"\"\"\n",
    "    # Calculate P(email|spam) and P(email|ham)\n",
    "    prob_email_given_spam = prob_email_given_class(treated_email, 'spam', word_frequency, class_frequency)\n",
    "    prob_email_given_ham = prob_email_given_class(treated_email, 'ham', word_frequency, class_frequency)\n",
    "    \n",
    "    # Calculate prior probabilities\n",
    "    total_emails = class_frequency['spam'] + class_frequency['ham']\n",
    "    p_spam = class_frequency['spam'] / total_emails\n",
    "    p_ham = class_frequency['ham'] / total_emails\n",
    "    \n",
    "    # Calculate posterior probabilities\n",
    "    spam_likelihood = p_spam * prob_email_given_spam\n",
    "    ham_likelihood = p_ham * prob_email_given_ham\n",
    "    \n",
    "    if return_likelihood:\n",
    "        return (spam_likelihood, ham_likelihood)\n",
    "    \n",
    "    return 1 if spam_likelihood >= ham_likelihood else 0\n",
    "\n",
    "def log_naive_bayes(treated_email, word_frequency, class_frequency, return_likelihood=False):\n",
    "    \"\"\"\n",
    "    Log-space Naive Bayes classifier for numerical stability.\n",
    "    \n",
    "    Args:\n",
    "        treated_email: Preprocessed email content\n",
    "        word_frequency: Word frequency dictionary\n",
    "        class_frequency: Class frequency dictionary\n",
    "        return_likelihood: Whether to return log-likelihood values\n",
    "        \n",
    "    Returns:\n",
    "        int: 1 for spam, 0 for ham (or log-likelihood tuple if requested)\n",
    "    \"\"\"\n",
    "    # Calculate log P(email|spam) and log P(email|ham)\n",
    "    log_prob_email_given_spam = log_prob_email_given_class(treated_email, 'spam', word_frequency, class_frequency)\n",
    "    log_prob_email_given_ham = log_prob_email_given_class(treated_email, 'ham', word_frequency, class_frequency)\n",
    "    \n",
    "    # Calculate log prior probabilities\n",
    "    total_emails = class_frequency['spam'] + class_frequency['ham']\n",
    "    log_p_spam = np.log(class_frequency['spam'] / total_emails)\n",
    "    log_p_ham = np.log(class_frequency['ham'] / total_emails)\n",
    "    \n",
    "    # Calculate log posterior probabilities\n",
    "    log_spam_likelihood = log_p_spam + log_prob_email_given_spam\n",
    "    log_ham_likelihood = log_p_ham + log_prob_email_given_ham\n",
    "    \n",
    "    if return_likelihood:\n",
    "        return (log_spam_likelihood, log_ham_likelihood)\n",
    "    \n",
    "    return 1 if log_spam_likelihood >= log_ham_likelihood else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481f5205",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Training the Naive Bayes model by calculating word frequencies and class distributions from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab121653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Naive Bayes model...\n",
      "\n",
      "Model Training Summary:\n",
      "==============================\n",
      "Vocabulary size: 33,812 unique words\n",
      "Training emails:\n",
      "  - Ham: 3,468\n",
      "  - Spam: 1,114\n",
      "\n",
      "Sample Word Probabilities:\n",
      "----------------------------------------\n",
      "lottery    | P(word|spam)=0.0081 | P(word|ham)=0.0003\n",
      "meeting    | P(word|spam)=0.0081 | P(word|ham)=0.1886\n",
      "free       | P(word|spam)=0.1768 | P(word|ham)=0.0995\n",
      "schedule   | P(word|spam)=0.0090 | P(word|ham)=0.1029\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "print(\"Training Naive Bayes model...\")\n",
    "word_frequency = get_word_frequency(X_train, Y_train)\n",
    "class_frequency = {'ham': sum(Y_train == 0), 'spam': sum(Y_train == 1)}\n",
    "\n",
    "print(\"\\nModel Training Summary:\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"Vocabulary size: {len(word_frequency):,} unique words\")\n",
    "print(f\"Training emails:\")\n",
    "print(f\"  - Ham: {class_frequency['ham']:,}\")\n",
    "print(f\"  - Spam: {class_frequency['spam']:,}\")\n",
    "\n",
    "# Example: Show probability of key words\n",
    "sample_words = ['lottery', 'meeting', 'free', 'schedule']\n",
    "print(f\"\\nSample Word Probabilities:\")\n",
    "print(\"-\" * 40)\n",
    "for word in sample_words:\n",
    "    if word in word_frequency:\n",
    "        p_spam = prob_word_given_class(word, 'spam', word_frequency, class_frequency)\n",
    "        p_ham = prob_word_given_class(word, 'ham', word_frequency, class_frequency)\n",
    "        print(f\"{word:10} | P(word|spam)={p_spam:.4f} | P(word|ham)={p_ham:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4068248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_positives(Y_true, Y_pred):\n",
    "    \"\"\"Count true positives (correctly identified spam)\"\"\"\n",
    "    return sum(1 for i in range(len(Y_true)) if Y_true[i] == 1 and Y_pred[i] == 1)\n",
    "\n",
    "def get_true_negatives(Y_true, Y_pred):\n",
    "    \"\"\"Count true negatives (correctly identified ham)\"\"\"\n",
    "    return sum(1 for i in range(len(Y_true)) if Y_true[i] == 0 and Y_pred[i] == 0)\n",
    "\n",
    "def get_false_positives(Y_true, Y_pred):\n",
    "    \"\"\"Count false positives (ham classified as spam)\"\"\"\n",
    "    return sum(1 for i in range(len(Y_true)) if Y_true[i] == 0 and Y_pred[i] == 1)\n",
    "\n",
    "def get_false_negatives(Y_true, Y_pred):\n",
    "    \"\"\"Count false negatives (spam classified as ham)\"\"\"\n",
    "    return sum(1 for i in range(len(Y_true)) if Y_true[i] == 1 and Y_pred[i] == 0)\n",
    "\n",
    "def calculate_metrics(Y_true, Y_pred):\n",
    "    \"\"\"Calculate comprehensive evaluation metrics\"\"\"\n",
    "    tp = get_true_positives(Y_true, Y_pred)\n",
    "    tn = get_true_negatives(Y_true, Y_pred)\n",
    "    fp = get_false_positives(Y_true, Y_pred)\n",
    "    fn = get_false_negatives(Y_true, Y_pred)\n",
    "    \n",
    "    accuracy = (tp + tn) / len(Y_true)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1_score,\n",
    "        'true_positives': tp,\n",
    "        'true_negatives': tn,\n",
    "        'false_positives': fp,\n",
    "        'false_negatives': fn\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbb47b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions...\n",
      "\n",
      "Standard Naive Bayes Results\n",
      "============================\n",
      "Accuracy:  0.8482 (84.82%)\n",
      "Precision: 0.5957\n",
      "Recall:    0.9803\n",
      "F1-Score:  0.7411\n",
      "\n",
      "Confusion Matrix:\n",
      "True Positives:   249\n",
      "True Negatives:   723\n",
      "False Positives:  169\n",
      "False Negatives:    5\n",
      "\n",
      "Log-space Naive Bayes Results\n",
      "=============================\n",
      "Accuracy:  0.9921 (99.21%)\n",
      "Precision: 0.9842\n",
      "Recall:    0.9803\n",
      "F1-Score:  0.9822\n",
      "\n",
      "Confusion Matrix:\n",
      "True Positives:   249\n",
      "True Negatives:   888\n",
      "False Positives:    4\n",
      "False Negatives:    5\n",
      "Log-space implementation improved accuracy by 0.1440 (14.40%)\n",
      "This demonstrates the critical importance of numerical stability in ML!\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions using both models\n",
    "print(\"Generating predictions...\")\n",
    "Y_pred_standard = [naive_bayes(email, word_frequency, class_frequency) for email in X_test]\n",
    "Y_pred_log = [log_naive_bayes(email, word_frequency, class_frequency) for email in X_test]\n",
    "\n",
    "# Calculate metrics for both models\n",
    "metrics_standard = calculate_metrics(Y_test, Y_pred_standard)\n",
    "metrics_log = calculate_metrics(Y_test, Y_pred_log)\n",
    "\n",
    "def display_results(metrics, model_name):\n",
    "    \"\"\"Display formatted evaluation results\"\"\"\n",
    "    print(f\"\\n{model_name}\")\n",
    "    print(\"=\" * len(model_name))\n",
    "    print(f\"Accuracy:  {metrics['accuracy']:.4f} ({metrics['accuracy']:.2%})\")\n",
    "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"Recall:    {metrics['recall']:.4f}\")\n",
    "    print(f\"F1-Score:  {metrics['f1_score']:.4f}\")\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(f\"True Positives:  {metrics['true_positives']:4d}\")\n",
    "    print(f\"True Negatives:  {metrics['true_negatives']:4d}\")\n",
    "    print(f\"False Positives: {metrics['false_positives']:4d}\")\n",
    "    print(f\"False Negatives: {metrics['false_negatives']:4d}\")\n",
    "\n",
    "display_results(metrics_standard, \"Standard Naive Bayes Results\")\n",
    "display_results(metrics_log, \"Log-space Naive Bayes Results\")\n",
    "\n",
    "# Highlight the improvement\n",
    "improvement = metrics_log['accuracy'] - metrics_standard['accuracy']\n",
    "print(f\"Log-space implementation improved accuracy by {improvement:.4f} ({improvement:.2%})\")\n",
    "print(f\"This demonstrates the critical importance of numerical stability in ML!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7378eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Stability Analysis\n",
      "========================================\n",
      "Email length: 262 words\n",
      "True label: Ham\n",
      "Standard NB prediction: Spam\n",
      "Log-space NB prediction: Ham\n",
      "\n",
      "Likelihood Analysis:\n",
      "Standard - Spam: 0.00e+00, Ham: 0.00e+00\n",
      "Log-space - Spam: -1161.60, Ham: -854.10\n",
      "\n",
      "âš ï¸  NUMERICAL UNDERFLOW DETECTED!\n",
      "Standard implementation suffers from floating-point precision limits.\n",
      "Log-space implementation maintains numerical stability.\n"
     ]
    }
   ],
   "source": [
    "# Find an email where the models disagree\n",
    "disagreement_indices = [i for i in range(len(Y_pred_standard)) \n",
    "                       if Y_pred_standard[i] != Y_pred_log[i]]\n",
    "\n",
    "if disagreement_indices:\n",
    "    idx = disagreement_indices[0]\n",
    "    sample_email = X_test[idx]\n",
    "    \n",
    "    print(\"Numerical Stability Analysis\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Email length: {len(sample_email)} words\")\n",
    "    print(f\"True label: {'Spam' if Y_test[idx] == 1 else 'Ham'}\")\n",
    "    print(f\"Standard NB prediction: {'Spam' if Y_pred_standard[idx] == 1 else 'Ham'}\")\n",
    "    print(f\"Log-space NB prediction: {'Spam' if Y_pred_log[idx] == 1 else 'Ham'}\")\n",
    "    \n",
    "    # Show likelihood values\n",
    "    spam_like, ham_like = naive_bayes(sample_email, word_frequency, class_frequency, return_likelihood=True)\n",
    "    log_spam_like, log_ham_like = log_naive_bayes(sample_email, word_frequency, class_frequency, return_likelihood=True)\n",
    "    \n",
    "    print(f\"\\nLikelihood Analysis:\")\n",
    "    print(f\"Standard - Spam: {spam_like:.2e}, Ham: {ham_like:.2e}\")\n",
    "    print(f\"Log-space - Spam: {log_spam_like:.2f}, Ham: {log_ham_like:.2f}\")\n",
    "    \n",
    "    if spam_like == 0 and ham_like == 0:\n",
    "        print(\"\\nâš ï¸  NUMERICAL UNDERFLOW DETECTED!\")\n",
    "        print(\"Standard implementation suffers from floating-point precision limits.\")\n",
    "        print(\"Log-space implementation maintains numerical stability.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5097b39a",
   "metadata": {},
   "source": [
    "## Demo and Conclusion\n",
    "\n",
    "### Interactive Email Classification\n",
    "\n",
    "Test the trained model with sample emails to demonstrate its capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51ff700a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMAIL CLASSIFICATION DEMO\n",
      "==================================================\n",
      "\n",
      "1. Email: 'Click here to win a lottery ticket and claim your prize NOW!'\n",
      "   Expected: Spam | Predicted: Spam âœ…\n",
      "\n",
      "2. Email: 'Our meeting will happen in the main office. Please be there ...'\n",
      "   Expected: Ham | Predicted: Ham âœ…\n",
      "\n",
      "3. Email: 'FREE MONEY! Act now to claim your $1000 reward! Limited time...'\n",
      "   Expected: Spam | Predicted: Spam âœ…\n",
      "\n",
      "4. Email: 'Please review the quarterly report attached to this email. T...'\n",
      "   Expected: Ham | Predicted: Ham âœ…\n",
      "\n",
      "5. Email: 'You have won $10,000! Click here to claim your prize immedia...'\n",
      "   Expected: Spam | Predicted: Spam âœ…\n",
      "\n",
      "6. Email: 'The project deadline has been extended to next Friday. Let m...'\n",
      "   Expected: Ham | Predicted: Ham âœ…\n",
      "\n",
      "Demo Accuracy: 6/6 (100.0%)\n"
     ]
    }
   ],
   "source": [
    "def classify_email(email_text, show_details=False):\n",
    "    \"\"\"\n",
    "    Classify a single email and optionally show detailed analysis.\n",
    "    \n",
    "    Args:\n",
    "        email_text: Raw email text\n",
    "        show_details: Whether to show preprocessing steps and probabilities\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (prediction, confidence_info)\n",
    "    \"\"\"\n",
    "    # Preprocess the email\n",
    "    treated = preprocess_text(email_text)\n",
    "    \n",
    "    # Get predictions and probabilities\n",
    "    prediction = log_naive_bayes(treated, word_frequency, class_frequency)\n",
    "    log_spam_prob, log_ham_prob = log_naive_bayes(treated, word_frequency, class_frequency, return_likelihood=True)\n",
    "    \n",
    "    result = \"Spam\" if prediction == 1 else \"Ham\"\n",
    "    \n",
    "    if show_details:\n",
    "        print(f\"Preprocessed: {treated[:10]}...\" if len(treated) > 10 else f\"Preprocessed: {treated}\")\n",
    "        print(f\"Log probabilities - Spam: {log_spam_prob:.2f}, Ham: {log_ham_prob:.2f}\")\n",
    "        print(f\"Prediction: {result}\")\n",
    "    \n",
    "    return result, (log_spam_prob, log_ham_prob)\n",
    "\n",
    "# Test with sample emails\n",
    "test_emails = [\n",
    "    \"ðŸŽ¯ SPAM: Click here to win a lottery ticket and claim your prize NOW!\",\n",
    "    \"ðŸ“§ HAM: Our meeting will happen in the main office. Please be there on time.\",\n",
    "    \"ðŸŽ¯ SPAM: FREE MONEY! Act now to claim your $1000 reward! Limited time offer!\",\n",
    "    \"ðŸ“§ HAM: Please review the quarterly report attached to this email. Thanks!\",\n",
    "    \"ðŸŽ¯ SPAM: You have won $10,000! Click here to claim your prize immediately!\",\n",
    "    \"ðŸ“§ HAM: The project deadline has been extended to next Friday. Let me know if you have questions.\"\n",
    "]\n",
    "\n",
    "print(\"EMAIL CLASSIFICATION DEMO\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "correct_predictions = 0\n",
    "for i, email in enumerate(test_emails):\n",
    "    # Extract expected label from emoji\n",
    "    expected = \"Spam\" if \"ðŸŽ¯\" in email else \"Ham\"\n",
    "    clean_email = email.split(\": \", 1)[1]  # Remove emoji prefix\n",
    "    \n",
    "    prediction, _ = classify_email(clean_email)\n",
    "    is_correct = \"âœ…\" if prediction == expected else \"âŒ\"\n",
    "    \n",
    "    print(f\"\\n{i+1}. Email: '{clean_email[:60]}{'...' if len(clean_email) > 60 else ''}'\")\n",
    "    print(f\"   Expected: {expected} | Predicted: {prediction} {is_correct}\")\n",
    "    \n",
    "    if prediction == expected:\n",
    "        correct_predictions += 1\n",
    "\n",
    "print(f\"\\nDemo Accuracy: {correct_predictions}/{len(test_emails)} ({correct_predictions/len(test_emails):.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d2eae2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
